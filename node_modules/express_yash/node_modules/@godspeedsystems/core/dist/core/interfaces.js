"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.GSActor = exports.GSLogEvent = exports.GSContext = exports.GSCloudEvent = exports.GSStatus = exports.GSEachSeriesFunction = exports.GSEachParallelFunction = exports.GSIFFunction = exports.GSSwitchFunction = exports.GSParallelFunction = exports.GSDynamicFunction = exports.GSSeriesFunction = exports.GSFunction = void 0;
const lodash_1 = __importDefault(require("lodash"));
const parse_duration_1 = __importDefault(require("parse-duration"));
const api_1 = __importDefault(require("@opentelemetry/api"));
const logger_1 = require("../logger");
const utils_1 = require("./utils");
const scriptRuntime_1 = __importDefault(require("./scriptRuntime"));
const monitoring_1 = require("../telemetry/monitoring");
const config_1 = __importDefault(require("config"));
const tracer = api_1.default.trace.getTracer('my-service-tracer');
//import R from 'ramda';
/**
  * SPEC:
  * Lender's integration:
  * YAML workflow spec
  * project scaffolding
  * API schema spec (includes channel integration)
  * runtime interfaces
  *
  * DEV:
  * dev: runtime engine (execute workflow and includes adapters for different channels)
  * dev: telemetry
  * dev: special functions:
  *  http
  *  transformation
  *
  * Parallel:
  *   GS_data
  */
/**
 * About hooks:
 *
 * LOG EVENT HANDLING (including error)
 * OPTION A:
 *  Whether error happens or not, it can return multiple GSEvents of type: error, warning,
 *  debug, info. On error, the called Function MUST itself handle error internally.
 *  These events will be logged by the common code. If there is an event with error,
 *  the common code will straightaway jump to the finally block.
 * OPTION B:
 *  Dev logs all events himself within the function. And if there is an error,
 *  return GSError (preferred), or throw the error for default handling.
 *  On catching an error, the common code will straightaway jump to the finally block.
 *
 *
 *  NO RETURN (Or any return will be ignored)
 *  If a hook needs subsequent hooks or _function to read any data calculated by it,
 *  it must set that data as per the expected key in ctx.{private | shared}, for the subsequent
 *  logic to consume it. If it returns anything, it will be ignored and not passed to subsequent hooks.
 *
 */
class GSFunction extends Function {
    constructor(yaml, workflows, nativeFunctions, _fn, args, isSubWorkflow, fnScript) {
        var _a, _b, _c, _d;
        super('return arguments.callee._observability.apply(arguments.callee, arguments)');
        this.yaml = yaml;
        this.id = yaml.id || yaml.workflow_name;
        this.fn = _fn;
        this.workflow_name = yaml.workflow_name;
        this.workflows = workflows;
        this.nativeFunctions = nativeFunctions;
        this.fnScript = fnScript;
        if (args) {
            this.args = args;
            const str = JSON.stringify(args);
            if ((str.match(/<(.*?)%/) && str.includes('%>')) || str.match(/(^|\/):([^/]+)/)) {
                this.args_script = (0, utils_1.compileScript)(args);
            }
        }
        this.onError = yaml.on_error;
        if (this.onError && this.onError.response) {
            if (!(this.onError.response instanceof Function)) {
                this.onError.response = (0, utils_1.compileScript)(this.onError.response);
            }
        }
        if ((_a = this.yaml.authz) === null || _a === void 0 ? void 0 : _a.args) {
            this.yaml.authz.args = (0, utils_1.compileScript)((_b = this.yaml.authz) === null || _b === void 0 ? void 0 : _b.args);
        }
        this.retry = yaml.retry;
        if (this.retry) {
            if (this.retry.interval) {
                this.retry.interval = (0, parse_duration_1.default)(this.retry.interval.replace(/^PT/i, ''));
            }
            if (this.retry.min_interval) {
                this.retry.min_interval = (0, parse_duration_1.default)(this.retry.min_interval.replace(/^PT/i, ''));
            }
            if (this.retry.max_interval) {
                this.retry.max_interval = (0, parse_duration_1.default)(this.retry.max_interval.replace(/^PT/i, ''));
            }
        }
        this.isSubWorkflow = isSubWorkflow;
        if (this.yaml.logs) {
            this.logs = this.yaml.logs;
            if ((_c = this.logs) === null || _c === void 0 ? void 0 : _c.before) {
                if (!(this.logs.before.attributes instanceof Function)) {
                    this.logs.before.attributes.task_id = this.id;
                    this.logs.before.attributes.workflow_name = this.workflow_name;
                    this.logs.before.attributes = (0, utils_1.compileScript)(this.logs.before.attributes);
                }
            }
            if ((_d = this.logs) === null || _d === void 0 ? void 0 : _d.after) {
                if (!(this.logs.after.attributes instanceof Function)) {
                    this.logs.after.attributes.task_id = this.id;
                    this.logs.after.attributes.workflow_name = this.workflow_name;
                    this.logs.after.attributes = (0, utils_1.compileScript)(this.logs.after.attributes);
                }
            }
        }
        if (this.yaml.metrics) {
            this.metrics = this.yaml.metrics;
            // @ts-ignore
            for (let metric of this.metrics) {
                metric.labels.task_id = this.id;
                metric.labels.workflow_name = this.workflow_name;
                switch (metric.type) {
                    case 'counter':
                        metric.obj = new monitoring_1.promClient.Counter({
                            name: metric.name,
                            help: metric.help,
                            labelNames: Object.keys(metric.labels || {})
                        });
                        break;
                    case 'gauge':
                        metric.obj = new monitoring_1.promClient.Gauge({
                            name: metric.name,
                            help: metric.help,
                            labelNames: Object.keys(metric.labels || {})
                        });
                        break;
                    case 'histogram':
                        metric.obj = new monitoring_1.promClient.Histogram({
                            name: metric.name,
                            help: metric.help,
                            labelNames: Object.keys(metric.labels || {})
                        });
                        break;
                    case 'summary':
                        metric.obj = new monitoring_1.promClient.Summary({
                            name: metric.name,
                            help: metric.help,
                            labelNames: Object.keys(metric.labels || {})
                        });
                        break;
                    default:
                        logger_1.logger.error({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'Invalid metric type %s, it should be one of counter,summary,histogram,gauge', metric.type);
                        process.exit(1);
                }
                for (let key of Object.keys(metric)) {
                    if (!['type', 'name', 'obj', 'timer', 'help'].includes(key)) {
                        metric[key] = (0, utils_1.compileScript)(metric[key]);
                    }
                }
            }
        }
        //caching
        if (this.yaml.caching) {
            this.caching = (0, utils_1.compileScript)(this.yaml.caching);
        }
    }
    _internalCall(ctx, taskValue) {
        var _a, _b;
        return __awaiter(this, void 0, void 0, function* () {
            if ((_a = this.logs) === null || _a === void 0 ? void 0 : _a.before) {
                const log = this.logs.before;
                //@ts-ignore
                ctx.childLogger[log.level](log.attributes ? yield (0, scriptRuntime_1.default)(ctx, log.attributes, taskValue) : null, `${log.message} %o`, log.params);
            }
            const timers = [];
            if (this.metrics) {
                for (let metric of this.metrics) {
                    if (metric.timer) {
                        //@ts-ignore
                        timers.push(metric.obj.startTimer());
                    }
                }
            }
            const status = yield this._call(ctx, taskValue);
            if (this.metrics) {
                for (let timer of timers) {
                    //@ts-ignore
                    timer();
                }
                for (let metric of this.metrics) {
                    let obj = metric.obj;
                    for (let key of Object.keys(metric)) {
                        if (!['type', 'name', 'obj', 'timer', 'help'].includes(key)) {
                            const val = yield (0, scriptRuntime_1.default)(ctx, metric[key], taskValue);
                            obj = obj[key](val);
                        }
                    }
                }
            }
            if ((_b = this.logs) === null || _b === void 0 ? void 0 : _b.after) {
                const log = this.logs.after;
                //@ts-ignore
                ctx.childLogger[log.level](log.attributes ? yield (0, scriptRuntime_1.default)(ctx, log.attributes, taskValue) : null, `${log.message} %o`, log.params);
            }
            return status;
        });
    }
    _observability(ctx, taskValue) {
        return __awaiter(this, void 0, void 0, function* () {
            if (this.yaml.trace) {
                let trace = this.yaml.trace;
                return tracer.startActiveSpan(trace.name, (span) => __awaiter(this, void 0, void 0, function* () {
                    if (trace.attributes) {
                        trace.attributes.task_id = this.id;
                        trace.attributes.workflow_name = this.workflow_name;
                        for (let attr in trace.attributes) {
                            span.setAttribute(attr, trace.attributes[attr]);
                        }
                    }
                    const status = yield this._internalCall(ctx, taskValue);
                    if (!status.success) {
                        span.setStatus({
                            //@ts-ignore
                            code: api_1.default.SpanStatusCode.ERROR,
                            message: 'Error'
                        });
                    }
                    span.end();
                    return status;
                }));
            }
            else {
                return this._internalCall(ctx, taskValue);
            }
        });
    }
    _executefn(ctx, taskValue) {
        return __awaiter(this, void 0, void 0, function* () {
            // final status to return
            let status;
            let args = this.args;
            try {
                ctx.childLogger.info({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'Executing handler %s %o', this.id, this.args);
                if (Array.isArray(this.args)) {
                    args = [...this.args];
                }
                else if (lodash_1.default.isPlainObject(this.args)) {
                    args = Object.assign({}, this.args);
                }
                else {
                    args = {};
                }
                ctx.childLogger.debug({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'Retry logic is %o', this.retry);
                ctx.childLogger.setBindings({ 'workflow_name': this.workflow_name, 'task_id': this.id });
                if (String(this.yaml.fn).startsWith('datasource.')) {
                    // If datasource is a script then evaluate it else load ctx.datasources as it is.
                    const [, datasourceName, entityType, method] = this.yaml.fn.split('.');
                    const datasource = ctx.datasources[datasourceName];
                    // so that prisma plugin get the entityName and method in plugin to execute respective method.
                    args.meta = {
                        fnNameInWorkflow: this.yaml.fn,
                        entityType,
                        method,
                    };
                    // REMOVE: this is not required, because now all the datasources are functions
                    // if (datasource instanceof Function) {
                    //   args.datasource = await evaluateScript(ctx, datasource, taskValue);
                    //   ctx.childLogger.info({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'datasource evaluated');
                    // } else {
                    //   args.datasource = datasource;
                    //   ctx.childLogger.info({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'datasource %o', args.datasource);
                    // }
                    // copy datasource headers to args.config.headers [This is useful to define the headers at datasource level
                    // so that datasource headers are passed to all the workflows using this datasource]
                    let headers = datasource.config.headers;
                    if (headers) {
                        args.config.headers = args.config.headers || {};
                        let tempObj = {};
                        Object.keys(Object.assign(Object.assign({}, headers), args.config.headers)).map(key => {
                            tempObj[key] = args.config.headers[key] || headers[key];
                        });
                        Object.assign(args.config.headers, tempObj);
                        Object.keys(args.config.headers).forEach(key => args.config.headers[key] === undefined && delete args.config.headers[key]);
                        ctx.childLogger.info({ 'workflow_name': this.workflow_name, 'task_id': this.id }, `settings datasource headers: %o`, args.config.headers);
                    }
                    // TODO: this will be moved to datasource plugin
                    // if (ds.authn && !datasource.authn_response) {
                    //   ctx.childLogger.info({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'Executing datasource authn workflow');
                    //   datasource.authn_response = await authnWorkflow(ds, ctx);
                    // }
                    // TODO: this will be moved to datasource plugin
                    // if (ds.before_method_hook) {
                    //   await ds.before_method_hook(ctx);
                    // }
                }
                // TODO: look back
                // if (args && ctx.inputs.metadata?.messagebus?.kafka) {  //com.gs.kafka will always have args
                //   args.kafka = ctx.inputs.metadata?.messagebus.kafka;
                // }
                // Generally all methods with retry will have some args
                if (args && this.retry) {
                    args.retry = this.retry;
                }
                let res;
                ctx.childLogger.setBindings({ 'workflow_name': this.workflow_name, 'task_id': this.id });
                if (Array.isArray(args)) {
                    res = yield this.fn(...[ctx, args]);
                }
                else {
                    res = yield this.fn(ctx, args);
                }
                ctx.childLogger.info({ 'workflow_name': this.workflow_name, 'task_id': this.id }, `Result of _executeFn ${this.id} %o`, res);
                if (res instanceof GSStatus) {
                    status = res;
                }
                else {
                    if (typeof (res) == 'object' && (res.success !== undefined || res.code !== undefined)) {
                        //Some framework functions like HTTP return an object in following format. Check if that is the case.
                        //All framework functions are expected to set success as boolean variable. Can not be null.
                        let { success, code, data, message, headers, exitWithStatus } = res;
                        status = new GSStatus(success, code, message, data, headers);
                        //Check if exitWithStatus is set in the res object. If it is set then return by setting ctx.exitWithStatus else continue.
                        if (exitWithStatus) {
                            ctx.exitWithStatus = status;
                        }
                    }
                    else {
                        //This function gives a non GSStatus compliant return, then create a new GSStatus and set in the output for this function
                        status = new GSStatus(true, 200, //Default code be 200 for now
                        undefined, res
                        //message: skip
                        //code: skip
                        );
                    }
                }
            }
            catch (err) {
                ctx.childLogger.error({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'Caught error from execution in task id: %s, error: %s', this.id, err);
                status = new GSStatus(false, 500, err.message, `Caught error from execution in task id: ${this.id}, error: ${err}`);
            }
            // TODO: move it to datasource
            // if (args.datasource?.after_method_hook) {
            //   ctx.outputs.current_output = status;
            //   await args.datasource.after_method_hook(ctx);
            // }
            return status;
        });
    }
    handleError(ctx, status, taskValue) {
        return __awaiter(this, void 0, void 0, function* () {
            if (!status.success) {
                /**
                * If the call had an error, set that in events so that we can send it to the telemetry backend.
                */
                ctx.addLogEvent(new GSLogEvent('ERROR', ctx.outputs));
                if (this.onError) {
                    ctx.outputs[this.id] = status;
                    if (this.onError.response instanceof Function) {
                        //The script may need the output of the task so far, for the transformation logic.
                        //So set the status in outputs, against this task's id
                        const res = yield (0, scriptRuntime_1.default)(ctx, this.onError.response, taskValue);
                        if (typeof res === 'object' && !(res.success === undefined && res.code === undefined)) { //Meaning the script is returning GS Status compatible response
                            let { success, code, data, message, headers } = res;
                            status = new GSStatus(success, code, message, data, headers);
                        }
                        else {
                            //This function gives a non GSStatus compliant return, then create a new GSStatus and set in the output for this function
                            status = new GSStatus(true, 200, //Default code be 200 for now
                            undefined, res);
                        }
                    }
                    else if (this.onError.response) {
                        status.data = this.onError.response;
                    }
                    else if (this.onError.tasks) {
                        status = yield this.onError.tasks(ctx);
                    }
                    if (this.onError.log_attributes) {
                        const error = {};
                        const logAttributes = this.onError.log_attributes;
                        for (let key in logAttributes) {
                            const script = (0, utils_1.compileScript)(logAttributes[key]);
                            error[key] = yield (0, scriptRuntime_1.default)(ctx, script, taskValue);
                        }
                        ctx.childLogger.setBindings({ error });
                    }
                    if (this.onError.continue === false) {
                        ctx.childLogger.debug({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'exiting on error %s', this.id);
                        ctx.exitWithStatus = status;
                    }
                }
                else {
                    if (ctx.exitWithStatus) {
                        ctx.exitWithStatus = status;
                    }
                }
            }
            ctx.outputs[this.id] = status;
            return status;
        });
    }
    /**
     *
     * @param instruction
     * @param ctx
     */
    _call(ctx, taskValue) {
        var _a, _b;
        return __awaiter(this, void 0, void 0, function* () {
            let status;
            let caching = null;
            let redisClient;
            try {
                ctx.childLogger.info({ 'workflow_name': this.workflow_name, 'task_id': this.id }, '_call invoked with task value %s %o', this.id, taskValue);
                let prismaArgs;
                ctx.childLogger.setBindings({ 'workflow_name': this.workflow_name, 'task_id': this.id });
                if (this.yaml.authz) {
                    ctx.childLogger.info({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'invoking authz workflow, creating new ctx');
                    let args = yield (0, scriptRuntime_1.default)(ctx, this.yaml.authz.args, taskValue);
                    const newCtx = ctx.cloneWithNewData(args);
                    let allow = yield this.yaml.authz(newCtx, taskValue);
                    if (allow.success) {
                        if (allow.data === false) {
                            ctx.exitWithStatus = new GSStatus(false, 403, allow.message || 'Unauthorized');
                            return ctx.exitWithStatus;
                        }
                        else if (lodash_1.default.isPlainObject(allow.data)) {
                            prismaArgs = allow.data;
                        }
                    }
                }
                if (this.caching) {
                    caching = yield (0, scriptRuntime_1.default)(ctx, this.caching, taskValue);
                    // @ts-ignore
                    redisClient = global.datasources[config_1.default.caching].client;
                    if (caching === null || caching === void 0 ? void 0 : caching.invalidate) {
                        ctx.childLogger.info({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'invalidating cache for %s', caching === null || caching === void 0 ? void 0 : caching.invalidate);
                        yield redisClient.del(caching.invalidate);
                    }
                    if (!(caching === null || caching === void 0 ? void 0 : caching.force)) {
                        // check in cache and return
                        status = yield redisClient.get(caching === null || caching === void 0 ? void 0 : caching.key);
                        if (status) {
                            ctx.childLogger.info({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'reading result from cache');
                            status = JSON.parse(status);
                            ctx.outputs[this.id] = status;
                            return status;
                        }
                    }
                }
                let args = this.args;
                if (this.args_script) {
                    args = yield (0, scriptRuntime_1.default)(ctx, this.args_script, taskValue);
                    if (args == 'Error in parsing script') {
                        throw ctx.exitWithStatus;
                    }
                }
                ctx.childLogger.info({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'args after evaluation: %s %o', this.id, args);
                if (prismaArgs) {
                    args.data = lodash_1.default.merge(args.data, prismaArgs);
                    ctx.childLogger.info({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'merged args with authz args.data: %o', args);
                }
                ctx.childLogger.setBindings({ 'workflow_name': '', 'task_id': '' });
                if (this.fnScript) {
                    ctx.childLogger.setBindings({ 'workflow_name': this.workflow_name, 'task_id': this.id });
                    let s = yield (0, scriptRuntime_1.default)(ctx, this.fnScript, taskValue);
                    ctx.childLogger.setBindings({ 'workflow_name': '', 'task_id': '' });
                    this.fn = (_a = this.nativeFunctions) === null || _a === void 0 ? void 0 : _a[s];
                    if (!this.fn) {
                        this.fn = (_b = this.workflows) === null || _b === void 0 ? void 0 : _b[s];
                        this.isSubWorkflow = true;
                    }
                    ctx.childLogger.info({ 'workflow_name': this.workflow_name, 'task_id': this.id }, `invoking dynamic fn: ${s}`);
                }
                if (this.fn instanceof GSFunction) {
                    if (this.isSubWorkflow) {
                        ctx.childLogger.info({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'isSubWorkflow, creating new ctx');
                        ctx.childLogger.setBindings({ 'workflow_name': this.workflow_name, 'task_id': this.id });
                        const newCtx = ctx.cloneWithNewData(args);
                        ctx.childLogger.setBindings({ 'workflow_name': '', 'task_id': '' });
                        status = yield this.fn(newCtx, taskValue);
                    }
                    else {
                        ctx.childLogger.info({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'No isSubWorkflow, continuing in the same ctx');
                        status = yield this.fn(ctx, taskValue);
                    }
                }
                else {
                    this.args = args;
                    status = yield this._executefn(ctx, taskValue);
                }
            }
            catch (err) {
                ctx.childLogger.error({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'Caught error in evaluation in task id: %s, error: %o', this.id, err);
                status = new GSStatus(false, 500, err.message, `Caught error from execution in task id ${this.id}`);
            }
            status = yield this.handleError(ctx, status, taskValue);
            if (caching && caching.key) {
                if ((status === null || status === void 0 ? void 0 : status.success) || caching.cache_on_failure) {
                    ctx.childLogger.info({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'Store result in cache');
                    yield redisClient.set(caching.key, JSON.stringify(status), { EX: caching.expires });
                }
            }
            return status;
        });
    }
    ;
}
exports.GSFunction = GSFunction;
class GSSeriesFunction extends GSFunction {
    _call(ctx, taskValue) {
        return __awaiter(this, void 0, void 0, function* () {
            ctx.childLogger.info({ 'workflow_name': this.workflow_name, 'task_id': this.id }, `GSSeriesFunction. Executing tasks with ids: ${this.args.map((task) => task.id)}`);
            let ret;
            for (const child of this.args) {
                ret = yield child(ctx, taskValue);
                if (ctx.exitWithStatus) {
                    if (child.yaml.isEachParallel) {
                        ctx.childLogger.debug({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'isEachParallel: %s, ret: %o', child.yaml.isEachParallel, ret);
                        ctx.outputs[this.id] = ret;
                        return ret;
                    }
                    else {
                        ctx.outputs[this.id] = ctx.exitWithStatus;
                        return ctx.exitWithStatus;
                    }
                }
            }
            ctx.childLogger.setBindings({ 'workflow_name': this.workflow_name, 'task_id': this.id });
            ctx.childLogger.debug({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'this.id: %s, output: %o', this.id, ret.data);
            ctx.outputs[this.id] = ret;
            return ret;
        });
    }
}
exports.GSSeriesFunction = GSSeriesFunction;
class GSDynamicFunction extends GSFunction {
    _call(ctx, taskValue) {
        return __awaiter(this, void 0, void 0, function* () {
            ctx.childLogger.debug({ 'workflow_name': this.workflow_name, 'task_id': this.id }, `GSDynamicFunction. Executing tasks with ids: ${this.args.map((task) => task.id)}`);
            let ret;
            for (const child of this.args) {
                ret = yield child(ctx, taskValue);
                if (ctx.exitWithStatus) {
                    ctx.outputs[this.id] = ctx.exitWithStatus;
                    return ctx.exitWithStatus;
                }
            }
            ctx.childLogger.debug({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'this.id: %s, output: %s', this.id, ret.data);
            if (ret.success && typeof (ret.data) === 'string') {
                ctx.outputs[this.id] = yield this.workflows[ret.data](ctx, taskValue);
            }
            else {
                return this.handleError(ctx, ret, taskValue);
            }
            return ctx.outputs[this.id];
        });
    }
}
exports.GSDynamicFunction = GSDynamicFunction;
class GSParallelFunction extends GSFunction {
    _call(ctx, taskValue) {
        return __awaiter(this, void 0, void 0, function* () {
            ctx.childLogger.debug({ 'workflow_name': this.workflow_name, 'task_id': this.id }, `GSParallelFunction. Executing tasks with ids: ${this.args.map((task) => task.id)}`);
            const promises = [];
            for (const child of this.args) {
                promises.push(child(ctx, taskValue));
            }
            yield Promise.all(promises);
            const outputs = [];
            const status = new GSStatus(true, 200, '', outputs);
            let output;
            for (const child of this.args) {
                output = ctx.outputs[child.id];
                outputs.push(output);
            }
            ctx.outputs[this.id] = status;
            return status;
        });
    }
}
exports.GSParallelFunction = GSParallelFunction;
class GSSwitchFunction extends GSFunction {
    constructor(yaml, workflows, nativeFunctions, _fn, args, isSubWorkflow) {
        super(yaml, workflows, nativeFunctions, _fn, args, isSubWorkflow);
        const [condition, cases] = this.args;
        if (typeof (condition) == 'string' && condition.match(/<(.*?)%/) && condition.includes('%>')) {
            this.condition_script = (0, utils_1.compileScript)(condition);
        }
    }
    _call(ctx, taskValue) {
        return __awaiter(this, void 0, void 0, function* () {
            ctx.childLogger.info({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'GSSwitchFunction');
            ctx.childLogger.debug({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'inside switch executor: %o', this.args);
            // tasks incase of series, parallel and condition, cases should be converted to args
            let [value, cases] = this.args;
            ctx.childLogger.debug({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'condition: %s', value);
            if (this.condition_script) {
                ctx.childLogger.setBindings({ 'workflow_name': this.workflow_name, 'task_id': this.id });
                value = yield (0, scriptRuntime_1.default)(ctx, this.condition_script, taskValue);
                ctx.childLogger.setBindings({ 'workflow_name': '', 'task_id': '' });
            }
            if (cases[value]) {
                yield cases[value](ctx, taskValue);
                ctx.outputs[this.id] = ctx.outputs[cases[value].id];
            }
            else {
                //check for default otherwise error
                if (cases.default) {
                    yield cases.default(ctx, taskValue);
                    ctx.outputs[this.id] = ctx.outputs[cases.default.id];
                }
                else {
                    //error
                    ctx.outputs[this.id] = new GSStatus(false, undefined, `case ${value} is missing and no default found in switch`);
                }
            }
            return ctx.outputs[this.id];
        });
    }
}
exports.GSSwitchFunction = GSSwitchFunction;
class GSIFFunction extends GSFunction {
    constructor(yaml, workflows, nativeFunctions, _fn, args, isSubWorkflow) {
        super(yaml, workflows, nativeFunctions, _fn, args, isSubWorkflow);
        const [condition, task, else_fn] = this.args;
        if (typeof (condition) == 'string' && condition.match(/<(.*?)%/) && condition.includes('%>')) {
            this.condition_script = (0, utils_1.compileScript)(condition);
        }
        this.task = task;
        this.else_fn = else_fn;
    }
    _call(ctx, taskValue) {
        return __awaiter(this, void 0, void 0, function* () {
            ctx.childLogger.info({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'GSIFFunction');
            ctx.childLogger.debug({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'inside GSIFFunction executor: %o', this.args);
            // tasks incase of series, parallel and condition, cases should be converted to args
            let [value, task] = this.args;
            ctx.childLogger.debug({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'condition: %s', value);
            if (this.condition_script) {
                ctx.childLogger.setBindings({ 'workflow_name': this.workflow_name, 'task_id': this.id });
                value = yield (0, scriptRuntime_1.default)(ctx, this.condition_script, taskValue);
                ctx.childLogger.setBindings({ 'workflow_name': '', 'task_id': '' });
            }
            if (value) {
                ctx.outputs[this.id] = yield this.task(ctx, taskValue);
            }
            else {
                if (this.else_fn) {
                    ctx.outputs[this.id] = yield this.else_fn(ctx, taskValue);
                }
                else {
                    ctx.outputs[this.id] = new GSStatus(false, undefined, `condition not matching and no else present`);
                }
            }
            return ctx.outputs[this.id];
        });
    }
}
exports.GSIFFunction = GSIFFunction;
class GSEachParallelFunction extends GSFunction {
    constructor(yaml, workflows, nativeFunctions, _fn, args, isSubWorkflow) {
        super(yaml, workflows, nativeFunctions, _fn, args, isSubWorkflow);
        const [value, cases] = this.args;
        if (typeof (value) == 'string' && value.match(/<(.*?)%/) && value.includes('%>')) {
            this.value_script = (0, utils_1.compileScript)(value);
        }
    }
    _call(ctx, taskValue) {
        return __awaiter(this, void 0, void 0, function* () {
            ctx.childLogger.debug({ 'workflow_name': this.workflow_name, 'task_id': this.id }, `GSEachParallelFunction. Executing tasks with ids: ${this.args.map((task) => task.id)}`);
            let [value, task] = this.args;
            ctx.childLogger.debug({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'value: %o', value);
            if (this.value_script) {
                ctx.childLogger.setBindings({ 'workflow_name': this.workflow_name, 'task_id': this.id });
                value = yield (0, scriptRuntime_1.default)(ctx, this.value_script, taskValue);
                ctx.childLogger.setBindings({ 'workflow_name': '', 'task_id': '' });
            }
            let i = 0;
            if (!Array.isArray(value)) {
                ctx.outputs[this.id] = new GSStatus(false, undefined, `GSEachParallel value is not an array`);
                return ctx.outputs[this.id];
            }
            const promises = [];
            let outputs = [];
            let status;
            let failedTasksCount = 0;
            for (const val of value) {
                promises.push(task(ctx, val));
            }
            outputs = yield Promise.all(promises);
            status = new GSStatus(true, 200, '', outputs);
            for (const output of outputs) {
                if (!output.success) {
                    failedTasksCount++;
                }
            }
            delete ctx.exitWithStatus;
            ctx.outputs[this.id] = status;
            // if the all the tasks get failed then check on_error at each_parallel loop level
            if (failedTasksCount == value.length && value.length > 0) {
                status.success = false;
                status.code = 500;
                return this.handleError(ctx, status, taskValue);
            }
            return status;
        });
    }
}
exports.GSEachParallelFunction = GSEachParallelFunction;
class GSEachSeriesFunction extends GSFunction {
    constructor(yaml, workflows, nativeFunctions, _fn, args, isSubWorkflow) {
        super(yaml, workflows, nativeFunctions, _fn, args, isSubWorkflow);
        const [value, cases] = this.args;
        if (typeof (value) == 'string' && value.match(/<(.*?)%/) && value.includes('%>')) {
            this.value_script = (0, utils_1.compileScript)(value);
        }
    }
    _call(ctx, taskValue) {
        return __awaiter(this, void 0, void 0, function* () {
            let [value, task] = this.args;
            ctx.childLogger.debug({ 'workflow_name': this.workflow_name, 'task_id': this.id }, 'value: %o', value);
            if (this.value_script) {
                ctx.childLogger.setBindings({ 'workflow_name': this.workflow_name, 'task_id': this.id });
                value = yield (0, scriptRuntime_1.default)(ctx, this.value_script, taskValue);
                ctx.childLogger.setBindings({ 'workflow_name': '', 'task_id': '' });
            }
            if (!Array.isArray(value)) {
                ctx.outputs[this.id] = new GSStatus(false, undefined, `GsEachSeries is value is not an array`);
                return ctx.outputs[this.id];
            }
            ctx.childLogger.debug({ 'workflow_name': this.workflow_name, 'task_id': this.id }, `GSEachSeriesFunction. Executing tasks with ids: ${this.args.map((task) => task.id)}`);
            const outputs = [];
            const status = new GSStatus(true, 200, '', outputs);
            let taskRes;
            let failedTasksCount = 0;
            for (const val of value) {
                taskRes = yield task(ctx, val);
                if (!taskRes.success) {
                    failedTasksCount++;
                }
                if (ctx.exitWithStatus) {
                    ctx.outputs[this.id] = ctx.exitWithStatus;
                    outputs.push(ctx.outputs[this.id]);
                    break; // break from for loop when continue is false for any task_value in each_sequential.
                }
                outputs.push(taskRes);
            }
            delete ctx.exitWithStatus; // exitWithStatus is removed from ctx so that other tasks (outside each_sequential loop) can be continued.
            ctx.outputs[this.id] = status;
            // if the all the tasks get failed then check on_error at each_sequential loop level
            if (failedTasksCount == value.length && value.length > 0) {
                status.success = false;
                status.code = 500;
                return this.handleError(ctx, status, taskValue);
            }
            return ctx.outputs[this.id];
        });
    }
}
exports.GSEachSeriesFunction = GSEachSeriesFunction;
/**
 * Final outcome of GSFunction execution.
 */
class GSStatus {
    constructor(success = true, code, message, data, headers) {
        this.message = message;
        this.code = code;
        this.success = success;
        this.headers = headers;
        this.data = data;
    }
}
exports.GSStatus = GSStatus;
class GSCloudEvent {
    constructor(id, type, time, source, specversion, data, channel, actor, metadata) {
        this.id = id;
        this.type = type;
        this.channel = channel;
        this.actor = actor;
        this.time = time;
        this.metadata = metadata;
        this.source = source;
        this.data = data;
        this.specversion = specversion;
    }
    cloneWithNewData(data) {
        return new GSCloudEvent(this.id, this.type, this.time, this.source, this.specversion, lodash_1.default.cloneDeep(data), this.channel, this.actor, this.metadata);
    }
}
exports.GSCloudEvent = GSCloudEvent;
/**
 * __actor (alias to __event.actor), __vars, __config, __src, __modules, __env, __event, __res (starting from the first parent span), __args (of the running GS instruction)
 */
class GSContext {
    constructor(config, datasources, event, mappings, plugins, logger, childLogger) {
        this.log_events = [];
        this.inputs = event;
        this.config = config;
        this.outputs = {};
        this.datasources = datasources;
        this.mappings = mappings;
        this.plugins = plugins;
        this.logger = logger;
        this.childLogger = childLogger;
        childLogger.debug('inputs for context %o', event.data);
    }
    cloneWithNewData(data) {
        var _a;
        return new GSContext(this.config, this.datasources, (_a = this.inputs) === null || _a === void 0 ? void 0 : _a.cloneWithNewData(data), this.mappings, this.plugins, this.logger, this.childLogger);
    }
    addLogEvent(event) {
        var _a;
        (_a = this.log_events) === null || _a === void 0 ? void 0 : _a.push(event);
        //also push to the logging backend
    }
}
exports.GSContext = GSContext;
/**
 *
 * Basic event information.this
 */
class GSLogEvent {
    constructor(type, data, attributes = {}, timestamp = new Date()) {
        this.type = type;
        this.data = data;
        this.attributes = attributes;
        this.timestamp = timestamp;
    }
}
exports.GSLogEvent = GSLogEvent;
class GSActor {
    constructor(type, tenant_id, name, id, data) {
        this.type = type;
        this.tenant_id = tenant_id;
        this.name = name;
        this.id = id;
        this.data = data;
    }
}
exports.GSActor = GSActor;
if (require.main === module) {
    // const createSpan = async (ctx: GSContext): Promise<GSContext> => {
    //   console.log('creating span')
    //   return ctx;
    // }
    // const closeSpan = async (ctx: GSContext): Promise<GSContext> => {
    //   //Close the telemetry object span
    //   //Send trace to the tracing backend
    //   console.log('closing span')
    //   return ctx;
    // }
    // const sendLogs = async (ctx: GSContext): Promise<GSContext> => {
    //   console.log('sending events', ctx.events)
    //   return ctx;
    // }
    // //Set pre auths
    // i.preAuthHooks.push(createSpan);
    // i.finally = [closeSpan, sendLogs];
    //i.execute(new GSContext({})).then((ctx) => console.log(JSON.stringify(ctx.outputs))).catch(console.log)
    //sync request : grpc and http
    //async request - response
}
/**
 * Thoughts on telemetry as middleware
 * Baed on telemetry requirements execute (GSFunction, ctx) call must create a span for itself in the ctx object
 * In the finally clause, the microservice or servler should add a hook on all Instruction it wants to trace.
 * Whether to create span for this instruction or not, will be included in the instruction export configuration.
 * Refer: https://docs.mindgrep.com/docs/scaffolding/intro#common-middleware-in-case-of-microservice
 */
/**
 *We have only events. Every http request is also an event.
* Event processor will process the workflow for the event.
* Every event can have multiple workflows attached to them.
* The workflow will execute and create the response.
* Then the adapter will send the response to one or more events on the channels
* specified in the API shema, with the response data & metadata.
 */ 
//# sourceMappingURL=interfaces.js.map